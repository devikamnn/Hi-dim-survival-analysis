# Hi-dim-survival-analysis
Survival analysis is a statistical methodology designed to analyze and predict the time to events. Here, the random variable is the survival time or the time until the occurrence of a specific event, which represents a qualitative change or the transition from one discrete state to another. In many fields of research,ranging from medicine and biology to engineering and social sciences, understanding this random variable is crucial. One of the main challenges for such time-to-event data is that usually the existence censored instances, i.e. the event of interest is not observed for these instances due to either the time limitation of the study period or losing track during the observation period. More precisely, certain instances have experienced an event (or labeled as event) and the information about the outcome variable for the remaining instances is only available until a specific time point in the study. Therefore, it is not suitable to directly apply predictive algorithms using standard statistical and machine learning approaches to analyze the survival data. Survival analysis provides mechanisms to handle such censored data problems. Originally developed in the context of clinical and biomedical research, survival analysis has since found widespread application in a variety of domains. These include estimating patient survival times, evaluating mechanical system reliability, modelling customer churn in business analytics, and understanding time-to-failure in industrial processes.
Traditionally, survival models such as the Kaplan-Meier estimator and Cox proportional hazards model have played central roles in the analysis of clinical and epidemiological data. However, with the increasing availability of largescale and high-dimensional data — particularly in genomics, health records,and precision medicine — conventional approaches often fall short due to issues like overfitting and instability. These challenges have spurred the development of new statistical and machine learning techniques that aim to enhance prediction accuracy and model interpretability in the presence of high-dimensional covariates.

We have studied various existing techniques for high dimensional survival data analysis and prediction. Some important methods were implemented using the TCGA PAN-CAN dataset. Classical and machine learning models were compared using C-index as the performance evaluation metric and we clearly see
how ensemble learning techniques help in better prediction accuracy. Some limitations include how the study is solely based on internal validation, which may limit the generalization of the results. The models having less interpretability—particularly for black-box methods like RSF,remains a challenge in clinical settings. The high dimensionality of genomic data also introduces noise, and while regularization limits this, feature selection and biological interpretability require further refinement.
Future work may include developing deep learning models for better predictions that lead to models capable of personalized medicine decisions.
